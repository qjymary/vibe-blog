"""
vibe-reviewer ä¸»æœåŠ¡

æä¾›æ•™ç¨‹è¯„ä¼°çš„æ ¸å¿ƒåŠŸèƒ½å…¥å£
"""
import os
import logging
import time
from typing import Optional, List, Dict, Any, Callable
from pathlib import Path

from .models.reviewer_models import (
    init_reviewer_tables,
    TutorialModel,
    ChapterModel,
    IssueModel,
    ImageModel,
)
from .schemas import (
    TutorialRequest,
    TutorialResponse,
    EvaluationStatus,
    ContentType,
)
from .git_service import GitService
from .preprocessing.document_processor import DocumentProcessor
from .preprocessing.image_extractor import ImageExtractor
from .pipeline.analyzer import ContentAnalyzer
from .pipeline.search_agent import SearchAgent
from .pipeline.reference_manager import ReferenceManager
from .pipeline.score_aggregator import ScoreAggregator
from .agents.questioner import Questioner
from .agents.depth_checker import DepthChecker
from .agents.quality_reviewer import QualityReviewer
from .agents.readability_checker import ReadabilityChecker
from .agents.improver import Improver

logger = logging.getLogger(__name__)

# å…¨å±€æœåŠ¡å®ä¾‹
_reviewer_service: Optional['ReviewerService'] = None


class ReviewerService:
    """
    vibe-reviewer ä¸»æœåŠ¡
    
    è´Ÿè´£åè°ƒæ•™ç¨‹è¯„ä¼°çš„å®Œæ•´æµç¨‹:
    1. Git ä»“åº“å…‹éš†/æ‹‰å–
    2. æ–‡æ¡£é¢„å¤„ç† (æ‰«æ .md æ–‡ä»¶)
    3. å›¾ç‰‡å¤šæ¨¡æ€ç†è§£
    4. æœç´¢å¢å¼ºè¯„ä¼°
    5. å¤šç»´åº¦è¯„åˆ†
    6. å¯æ“ä½œåé¦ˆç”Ÿæˆ
    """
    
    def __init__(self, llm_service=None, search_service=None, repos_dir: str = None):
        """
        åˆå§‹åŒ– ReviewerService
        
        Args:
            llm_service: LLM æœåŠ¡å®ä¾‹ (å¤ç”¨ vibe-blog)
            search_service: æœç´¢æœåŠ¡å®ä¾‹ (å¤ç”¨ vibe-blog)
            repos_dir: Git ä»“åº“æœ¬åœ°å­˜å‚¨ç›®å½•
        """
        self.llm_service = llm_service
        self.search_service = search_service
        
        # è®¾ç½®ä»“åº“å­˜å‚¨ç›®å½•
        if repos_dir is None:
            base_dir = Path(__file__).parent.parent
            repos_dir = str(base_dir / "data" / "repos")
        self.repos_dir = repos_dir
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        try:
            Path(repos_dir).mkdir(parents=True, exist_ok=True)
        except (OSError, IOError):
            logger.warning(f"æ— æ³•åˆ›å»ºä»“åº“ç›®å½•: {repos_dir}")
        
        logger.info(f"ReviewerService åˆå§‹åŒ–å®Œæˆ, repos_dir={repos_dir}")
    
    def add_tutorial(self, request: TutorialRequest) -> TutorialResponse:
        """
        æ·»åŠ æ•™ç¨‹
        
        Args:
            request: æ•™ç¨‹è¯·æ±‚
            
        Returns:
            æ•™ç¨‹å“åº”
        """
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = TutorialModel.get_by_git_url(request.git_url)
        if existing:
            logger.info(f"æ•™ç¨‹å·²å­˜åœ¨: {request.git_url}")
            return TutorialResponse(
                id=existing['id'],
                name=existing['name'],
                git_url=existing['git_url'],
                status=existing['status'],
                overall_score=existing['overall_score'] or 0,
                total_chapters=existing['total_chapters'] or 0,
                total_issues=existing['total_issues'] or 0,
                high_issues=existing['high_issues'] or 0,
                medium_issues=existing['medium_issues'] or 0,
                low_issues=existing['low_issues'] or 0,
                created_at=existing['created_at'],
                last_evaluated=existing['last_evaluated'],
            )
        
        # ä» URL æå–åç§°
        name = request.name
        if not name:
            name = request.git_url.rstrip('/').split('/')[-1]
            if name.endswith('.git'):
                name = name[:-4]
        
        # åˆ›å»ºæ•™ç¨‹è®°å½•
        tutorial_id = TutorialModel.create(
            name=name,
            git_url=request.git_url,
            branch=request.branch,
            enable_search=request.enable_search,
            max_search_rounds=request.max_search_rounds,
        )
        
        logger.info(f"æ•™ç¨‹å·²åˆ›å»º: id={tutorial_id}, name={name}")
        
        return TutorialResponse(
            id=tutorial_id,
            name=name,
            git_url=request.git_url,
            status=EvaluationStatus.PENDING.value,
        )
    
    def get_tutorial(self, tutorial_id: int) -> Optional[TutorialResponse]:
        """è·å–æ•™ç¨‹è¯¦æƒ…"""
        tutorial = TutorialModel.get_by_id(tutorial_id)
        if not tutorial:
            return None
        
        return TutorialResponse(
            id=tutorial['id'],
            name=tutorial['name'],
            git_url=tutorial['git_url'],
            status=tutorial['status'],
            overall_score=tutorial['overall_score'] or 0,
            total_chapters=tutorial['total_chapters'] or 0,
            total_issues=tutorial['total_issues'] or 0,
            high_issues=tutorial['high_issues'] or 0,
            medium_issues=tutorial['medium_issues'] or 0,
            low_issues=tutorial['low_issues'] or 0,
            created_at=tutorial['created_at'],
            last_evaluated=tutorial['last_evaluated'],
        )
    
    def list_tutorials(self) -> List[TutorialResponse]:
        """è·å–æ‰€æœ‰æ•™ç¨‹åˆ—è¡¨"""
        tutorials = TutorialModel.get_all()
        return [
            TutorialResponse(
                id=t['id'],
                name=t['name'],
                git_url=t['git_url'],
                status=t['status'],
                overall_score=t['overall_score'] or 0,
                total_chapters=t['total_chapters'] or 0,
                total_issues=t['total_issues'] or 0,
                high_issues=t['high_issues'] or 0,
                medium_issues=t['medium_issues'] or 0,
                low_issues=t['low_issues'] or 0,
                created_at=t['created_at'],
                last_evaluated=t['last_evaluated'],
            )
            for t in tutorials
        ]
    
    def delete_tutorial(self, tutorial_id: int) -> bool:
        """åˆ é™¤æ•™ç¨‹"""
        tutorial = TutorialModel.get_by_id(tutorial_id)
        if not tutorial:
            return False
        
        TutorialModel.delete(tutorial_id)
        logger.info(f"æ•™ç¨‹å·²åˆ é™¤: id={tutorial_id}")
        return True
    
    def get_chapters(self, tutorial_id: int) -> List[Dict]:
        """è·å–æ•™ç¨‹çš„æ‰€æœ‰ç« èŠ‚"""
        return ChapterModel.get_by_tutorial(tutorial_id)
    
    def get_chapter(self, chapter_id: int) -> Optional[Dict]:
        """è·å–ç« èŠ‚è¯¦æƒ…"""
        return ChapterModel.get_by_id(chapter_id)
    
    def get_issues(self, tutorial_id: int = None, chapter_id: int = None, 
                   severity: str = None) -> List[Dict]:
        """è·å–é—®é¢˜åˆ—è¡¨"""
        if chapter_id:
            return IssueModel.get_by_chapter(chapter_id)
        elif tutorial_id:
            return IssueModel.get_by_tutorial(tutorial_id, severity)
        return []
    
    def mark_issue_resolved(self, issue_id: int, resolved: bool = True) -> bool:
        """æ ‡è®°é—®é¢˜å·²è§£å†³"""
        IssueModel.mark_resolved(issue_id, resolved)
        return True
    
    def evaluate_tutorial_sync(
        self, 
        tutorial_id: int,
        on_progress: Callable[[Dict], None] = None,
        max_chapters: int = 50
    ) -> Dict:
        """
        è¯„ä¼°æ•™ç¨‹ (åŒæ­¥ç‰ˆæœ¬)
        
        Args:
            tutorial_id: æ•™ç¨‹ ID
            on_progress: è¿›åº¦å›è°ƒå‡½æ•°
            max_chapters: æœ€å¤§è¯„ä¼°ç« èŠ‚æ•°
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        start_time = time.time()
        tutorial = TutorialModel.get_by_id(tutorial_id)
        if not tutorial:
            raise ValueError(f"æ•™ç¨‹ä¸å­˜åœ¨: {tutorial_id}")
        
        def emit(event_type: str, **data):
            """å‘é€è¿›åº¦äº‹ä»¶"""
            if on_progress:
                on_progress({"type": event_type, **data})
        
        try:
            # ========== Step 1: Git å…‹éš†/æ‹‰å– ==========
            TutorialModel.update_status(tutorial_id, EvaluationStatus.CLONING.value)
            emit("log", level="info", message=f"ğŸ“¥ å¼€å§‹å…‹éš†ä»“åº“: {tutorial['git_url']}")
            emit("status", status="cloning", message="æ­£åœ¨å…‹éš†ä»“åº“...")
            
            git_service = GitService(self.repos_dir)
            local_path, has_update = git_service.clone_or_pull(
                tutorial['git_url'], 
                tutorial.get('branch', 'main')
            )
            
            emit("log", level="success", message=f"âœ… ä»“åº“å…‹éš†å®Œæˆ: {local_path}")
            emit("clone_complete", local_path=local_path, has_update=has_update)
            logger.info(f"ä»“åº“å…‹éš†å®Œæˆ: {local_path}")
            
            # ========== Step 2: æ‰«æ .md æ–‡ä»¶ ==========
            TutorialModel.update_status(tutorial_id, EvaluationStatus.SCANNING.value)
            emit("log", level="info", message="ğŸ” å¼€å§‹æ‰«æ Markdown æ–‡ä»¶...")
            emit("status", status="scanning", message="æ­£åœ¨æ‰«æ Markdown æ–‡ä»¶...")
            
            doc_processor = DocumentProcessor()
            md_files = doc_processor.scan_directory(local_path)
            
            emit("log", level="info", message=f"ğŸ“„ å‘ç° {len(md_files)} ä¸ª Markdown æ–‡ä»¶")
            
            # é™åˆ¶ç« èŠ‚æ•°é‡
            if len(md_files) > max_chapters:
                emit("log", level="warning", message=f"âš ï¸ ç« èŠ‚æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œåªè¯„ä¼°å‰ {max_chapters} ä¸ª")
                logger.warning(f"ç« èŠ‚æ•°é‡ {len(md_files)} è¶…è¿‡é™åˆ¶ {max_chapters}ï¼Œåªè¯„ä¼°å‰ {max_chapters} ä¸ª")
                md_files = md_files[:max_chapters]
            
            emit("log", level="success", message=f"âœ… æ‰«æå®Œæˆ: å‡†å¤‡è¯„ä¼° {len(md_files)} ä¸ªç« èŠ‚")
            emit("scan_complete", total_files=len(md_files), 
                 files=[f.file_path for f in md_files])
            logger.info(f"æ‰«æå®Œæˆ: æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶")
            
            # ========== Step 3: åˆ›å»º/æ›´æ–°ç« èŠ‚è®°å½• ==========
            chapters_to_evaluate = []
            for md_file in md_files:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸”æœªå˜åŒ– (å¢é‡æ›´æ–°)
                existing = ChapterModel.get_by_hash(tutorial_id, md_file.content_hash)
                if existing and existing.get('status') == 'completed':
                    logger.debug(f"ç« èŠ‚æœªå˜åŒ–ï¼Œè·³è¿‡: {md_file.file_path}")
                    continue
                
                # åˆ›å»ºæˆ–æ›´æ–°ç« èŠ‚
                chapter_id = ChapterModel.create(
                    tutorial_id=tutorial_id,
                    file_path=md_file.file_path,
                    file_name=md_file.file_name,
                    title=md_file.title,
                    chapter_order=md_file.order,
                    raw_content=md_file.content,
                    content_hash=md_file.content_hash,
                )
                
                chapters_to_evaluate.append({
                    'id': chapter_id,
                    'file_path': md_file.file_path,
                    'title': md_file.title,
                    'content': md_file.content,
                    'base_path': os.path.dirname(os.path.join(local_path, md_file.file_path)),
                })
            
            emit("chapters_ready", total=len(chapters_to_evaluate))
            
            # ========== Step 4: é€ç« è¯„ä¼° ==========
            TutorialModel.update_status(tutorial_id, EvaluationStatus.EVALUATING.value)
            
            # åˆå§‹åŒ–è¯„ä¼°ç»„ä»¶
            analyzer = ContentAnalyzer(self.llm_service) if self.llm_service else None
            search_agent = SearchAgent(self.search_service)
            ref_manager = ReferenceManager(self.llm_service)
            questioner = Questioner(self.llm_service) if self.llm_service else None
            depth_checker = DepthChecker(self.llm_service) if self.llm_service else None
            quality_reviewer = QualityReviewer(self.llm_service) if self.llm_service else None
            readability_checker = ReadabilityChecker(self.llm_service) if self.llm_service else None
            improver = Improver(self.llm_service) if self.llm_service else None
            score_aggregator = ScoreAggregator()
            image_extractor = ImageExtractor()
            
            total_issues = 0
            high_issues = 0
            medium_issues = 0
            low_issues = 0
            total_score = 0
            
            # ========== Step 4.0: ç”Ÿæˆç« èŠ‚æ‘˜è¦ï¼ˆç”¨äºä¸Šä¸‹æ–‡è¿è´¯æ€§æ£€æµ‹ï¼‰==========
            emit("log", level="info", message="ğŸ“ æ­£åœ¨ç”Ÿæˆç« èŠ‚æ‘˜è¦...")
            chapter_summaries = []
            for idx, chapter in enumerate(chapters_to_evaluate):
                # ä½¿ç”¨ LLM ç”Ÿæˆç®€çŸ­æ‘˜è¦
                if self.llm_service:
                    try:
                        summary_prompt = f"è¯·ç”¨1-2å¥è¯æ¦‚æ‹¬ä»¥ä¸‹å†…å®¹çš„æ ¸å¿ƒä¸»é¢˜å’Œè¦ç‚¹ï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼š\n\n{chapter['content'][:2000]}"
                        chapter_summary = self.llm_service.chat(
                            messages=[{"role": "user", "content": summary_prompt}]
                        )
                        chapter_summaries.append({
                            'title': chapter['title'] or chapter['file_path'],
                            'summary': chapter_summary[:200] if chapter_summary else ''
                        })
                    except Exception as e:
                        logger.warning(f"ç”Ÿæˆç« èŠ‚æ‘˜è¦å¤±è´¥: {e}")
                        chapter_summaries.append({
                            'title': chapter['title'] or chapter['file_path'],
                            'summary': ''
                        })
                else:
                    chapter_summaries.append({
                        'title': chapter['title'] or chapter['file_path'],
                        'summary': ''
                    })
            emit("log", level="success", message=f"âœ… ç« èŠ‚æ‘˜è¦ç”Ÿæˆå®Œæˆ: {len(chapter_summaries)} ä¸ª")
            
            for idx, chapter in enumerate(chapters_to_evaluate):
                chapter_id = chapter['id']
                content = chapter['content']
                
                # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå‰ä¸€ç« å’Œåä¸€ç« çš„æ‘˜è¦ï¼‰
                context = {
                    'prev_chapter': chapter_summaries[idx - 1] if idx > 0 else None,
                    'next_chapter': chapter_summaries[idx + 1] if idx < len(chapter_summaries) - 1 else None,
                    'chapter_index': idx + 1,
                    'total_chapters': len(chapters_to_evaluate),
                }
                
                emit("chapter_start", 
                     chapter_id=chapter_id, 
                     chapter_index=idx + 1,
                     total_chapters=len(chapters_to_evaluate),
                     file_path=chapter['file_path'])
                emit("log", level="info", message=f"ğŸ“– [{idx+1}/{len(chapters_to_evaluate)}] å¼€å§‹è¯„ä¼°: {chapter['title'] or chapter['file_path']}")
                
                try:
                    # 4.1 å†…å®¹åˆ†æ
                    emit("log", level="info", message="   ğŸ”¬ æ­£åœ¨åˆ†æå†…å®¹ç»“æ„...")
                    emit("chapter_step", chapter_id=chapter_id, step="analyze", status="start")
                    summary = analyzer.analyze(content) if analyzer else None
                    content_type = summary.content_type if summary else ContentType.UNKNOWN
                    emit("chapter_step", chapter_id=chapter_id, step="analyze", status="complete")
                    if summary:
                        emit("log", level="info", message=f"   âœ“ å†…å®¹åˆ†æå®Œæˆ: ç±»å‹={content_type.value}, ä¸»é¢˜={summary.topic[:30] if summary.topic else 'æœªçŸ¥'}...")
                    
                    # 4.2 æœç´¢å‚è€ƒèµ„æ–™ (å¦‚æœå¯ç”¨)
                    references = []
                    if tutorial.get('enable_search', True) and summary and summary.search_queries:
                        emit("log", level="info", message=f"   ğŸ” æ­£åœ¨æœç´¢å‚è€ƒèµ„æ–™ (å…³é”®è¯: {', '.join(summary.search_queries[:3])})")
                        emit("chapter_step", chapter_id=chapter_id, step="search", status="start")
                        search_results = search_agent.search_multi_round(
                            summary, 
                            max_rounds=tutorial.get('max_search_rounds', 2)
                        )
                        # è¯„ä¼°ç›¸å…³æ€§
                        search_results = ref_manager.evaluate_relevance(search_results, summary)
                        references = ref_manager.get_top_references(search_results, top_k=5)
                        emit("chapter_step", chapter_id=chapter_id, step="search", status="complete",
                             results_count=len(references))
                        emit("log", level="info", message=f"   âœ“ æœç´¢å®Œæˆ: æ‰¾åˆ° {len(references)} æ¡ç›¸å…³å‚è€ƒ")
                    
                    # 4.3 è¿½é—®æ£€æŸ¥ï¼ˆå‘ç°æ¨¡ç³Šç‚¹å’Œé—æ¼ï¼ŒåŒ…å«ä¸Šä¸‹æ–‡è¿è´¯æ€§æ£€æµ‹ï¼‰
                    emit("log", level="info", message="   â“ æ­£åœ¨è¿›è¡Œè¿½é—®æ£€æŸ¥...")
                    emit("chapter_step", chapter_id=chapter_id, step="question", status="start")
                    question_result = questioner.question(content, context=context) if questioner else None
                    emit("chapter_step", chapter_id=chapter_id, step="question", status="complete")
                    if question_result:
                        emit("log", level="info", message=f"   âœ“ è¿½é—®æ£€æŸ¥å®Œæˆ: è¯„åˆ†={question_result.get('score', 70)}, æ¨¡ç³Šç‚¹={len(question_result.get('issues', []))}")
                    
                    # 4.4 æ·±åº¦æ£€æŸ¥
                    emit("log", level="info", message="   ğŸ“Š æ­£åœ¨è¿›è¡Œæ·±åº¦æ£€æŸ¥...")
                    emit("chapter_step", chapter_id=chapter_id, step="depth", status="start")
                    depth_result = depth_checker.check(content, references) if depth_checker else None
                    emit("chapter_step", chapter_id=chapter_id, step="depth", status="complete")
                    if depth_result:
                        emit("log", level="info", message=f"   âœ“ æ·±åº¦æ£€æŸ¥å®Œæˆ: è¯„åˆ†={depth_result.score}, æ¨¡ç³Šç‚¹={len(depth_result.vague_points)}")
                    
                    # 4.4 è´¨é‡å®¡æ ¸
                    emit("log", level="info", message="   âœ… æ­£åœ¨è¿›è¡Œè´¨é‡å®¡æ ¸...")
                    emit("chapter_step", chapter_id=chapter_id, step="quality", status="start")
                    quality_result = quality_reviewer.review(content, references) if quality_reviewer else None
                    emit("chapter_step", chapter_id=chapter_id, step="quality", status="complete")
                    if quality_result:
                        emit("log", level="info", message=f"   âœ“ è´¨é‡å®¡æ ¸å®Œæˆ: è¯„åˆ†={quality_result.score}, é—®é¢˜={len(quality_result.issues)}")
                    
                    # 4.5 å¯è¯»æ€§æ£€æµ‹
                    emit("log", level="info", message="   ğŸ“– æ­£åœ¨æ£€æµ‹å¯è¯»æ€§...")
                    emit("chapter_step", chapter_id=chapter_id, step="readability", status="start")
                    readability_result = readability_checker.check(content) if readability_checker else None
                    emit("chapter_step", chapter_id=chapter_id, step="readability", status="complete")
                    if readability_result:
                        emit("log", level="info", message=f"   âœ“ å¯è¯»æ€§æ£€æµ‹å®Œæˆ: è¯„åˆ†={readability_result.score}, çº§åˆ«={readability_result.level.value}")
                    
                    # 4.6 ç”Ÿæˆæ”¹è¿›å»ºè®®
                    feedback = []
                    if improver and depth_result and quality_result and readability_result:
                        emit("log", level="info", message="   ğŸ’¡ æ­£åœ¨ç”Ÿæˆæ”¹è¿›å»ºè®®...")
                        emit("chapter_step", chapter_id=chapter_id, step="improve", status="start")
                        feedback = improver.generate(content, depth_result, quality_result, readability_result)
                        emit("chapter_step", chapter_id=chapter_id, step="improve", status="complete")
                        emit("log", level="info", message=f"   âœ“ æ”¹è¿›å»ºè®®ç”Ÿæˆå®Œæˆ: {len(feedback)} æ¡å»ºè®®")
                    
                    # 4.7 è®¡ç®—ç»¼åˆè¯„åˆ†
                    if depth_result and quality_result and readability_result:
                        overall_score, dimension_scores = score_aggregator.aggregate(
                            depth_result, quality_result, readability_result, content_type
                        )
                    else:
                        overall_score = 70
                        dimension_scores = None
                    
                    # 4.8 ç»Ÿè®¡é—®é¢˜
                    chapter_issues = []
                    
                    # è¿½é—®æ£€æŸ¥çš„é—®é¢˜
                    if question_result:
                        for issue in question_result.get('issues', []):
                            chapter_issues.append({
                                'category': 'questioner',
                                'issue_type': issue.issue_type if hasattr(issue, 'issue_type') else 'vague_claim',
                                'severity': issue.severity if hasattr(issue, 'severity') else 'medium',
                                'location': issue.location if hasattr(issue, 'location') else '',
                                'original_text': issue.original_text if hasattr(issue, 'original_text') else '',
                                'description': issue.description if hasattr(issue, 'description') else '',
                                'suggestion': issue.suggestion if hasattr(issue, 'suggestion') else '',
                            })
                    
                    # æ·±åº¦æ£€æŸ¥çš„é—®é¢˜
                    if depth_result:
                        for vp in depth_result.vague_points:
                            chapter_issues.append({
                                'category': 'depth',
                                'issue_type': 'vague_claim',
                                'severity': 'medium',
                                'location': vp.location,
                                'original_text': vp.original_text if hasattr(vp, 'original_text') else '',
                                'description': vp.issue,
                                'suggestion': vp.suggestion,
                            })
                    
                    if quality_result:
                        for issue in quality_result.issues:
                            chapter_issues.append({
                                'category': 'quality',
                                'issue_type': issue.issue_type,
                                'severity': issue.severity,
                                'location': issue.location,
                                'original_text': issue.original_text if hasattr(issue, 'original_text') else '',
                                'description': issue.description,
                                'suggestion': issue.suggestion,
                                'reference': issue.reference,
                            })
                    
                    if readability_result:
                        for issue in readability_result.issues:
                            chapter_issues.append({
                                'category': 'readability',
                                'issue_type': issue.issue_type,
                                'severity': issue.severity,
                                'location': issue.location,
                                'original_text': issue.original_text if hasattr(issue, 'original_text') else '',
                                'description': issue.description,
                                'suggestion': issue.suggestion,
                            })
                    
                    # 4.9 ä¿å­˜é—®é¢˜åˆ°æ•°æ®åº“
                    chapter_high = 0
                    chapter_medium = 0
                    chapter_low = 0
                    for issue in chapter_issues:
                        IssueModel.create(
                            chapter_id=chapter_id,
                            tutorial_id=tutorial_id,
                            **issue
                        )
                        if issue['severity'] == 'high':
                            chapter_high += 1
                        elif issue['severity'] == 'medium':
                            chapter_medium += 1
                        else:
                            chapter_low += 1
                    
                    # 4.10 æ›´æ–°ç« èŠ‚è¯„åˆ†
                    ChapterModel.update_scores(
                        chapter_id=chapter_id,
                        overall_score=overall_score,
                        depth_score=depth_result.score if depth_result else 70,
                        quality_score=quality_result.score if quality_result else 70,
                        readability_score=readability_result.score if readability_result else 70,
                        readability_level=readability_result.level.value if readability_result else 'normal',
                        total_issues=len(chapter_issues),
                        high_issues=chapter_high,
                        medium_issues=chapter_medium,
                        low_issues=chapter_low,
                    )
                    
                    # ç´¯è®¡ç»Ÿè®¡
                    total_issues += len(chapter_issues)
                    high_issues += chapter_high
                    medium_issues += chapter_medium
                    low_issues += chapter_low
                    total_score += overall_score
                    
                    # æ¨é€ç« èŠ‚å®Œæˆæ—¥å¿—
                    score_color = "ğŸŸ¢" if overall_score >= 80 else "ğŸŸ¡" if overall_score >= 60 else "ğŸ”´"
                    emit("log", level="success", 
                         message=f"   {score_color} ç« èŠ‚è¯„ä¼°å®Œæˆ: ç»¼åˆè¯„åˆ†={overall_score}, é—®é¢˜æ•°={len(chapter_issues)} (ğŸ”´{chapter_high} ğŸŸ¡{chapter_medium} ğŸŸ¢{chapter_low})")
                    
                    # æ¨é€ç« èŠ‚å®Œæˆäº‹ä»¶ (åŒ…å«é—®é¢˜è¯¦æƒ…)
                    emit("chapter_complete",
                         chapter_id=chapter_id,
                         chapter_index=idx + 1,
                         total_chapters=len(chapters_to_evaluate),
                         file_path=chapter['file_path'],
                         title=chapter['title'],
                         overall_score=overall_score,
                         depth_score=depth_result.score if depth_result else 70,
                         quality_score=quality_result.score if quality_result else 70,
                         readability_score=readability_result.score if readability_result else 70,
                         total_issues=len(chapter_issues),
                         high_issues=chapter_high,
                         medium_issues=chapter_medium,
                         low_issues=chapter_low,
                         issues=chapter_issues[:5])  # åªæ¨é€å‰5ä¸ªé—®é¢˜ï¼Œé¿å…æ•°æ®è¿‡å¤§
                    
                except Exception as e:
                    logger.error(f"ç« èŠ‚è¯„ä¼°å¤±è´¥: {chapter['file_path']}, é”™è¯¯: {e}")
                    emit("log", level="error", message=f"   âŒ ç« èŠ‚è¯„ä¼°å¤±è´¥: {str(e)}")
                    emit("chapter_error", chapter_id=chapter_id, error=str(e))
            
            # ========== Step 5: æ±‡æ€»ç»“æœ ==========
            emit("log", level="info", message="ğŸ“Š æ­£åœ¨æ±‡æ€»è¯„ä¼°ç»“æœ...")
            duration = int(time.time() - start_time)
            avg_score = total_score / len(chapters_to_evaluate) if chapters_to_evaluate else 0
            
            TutorialModel.update_scores(
                tutorial_id=tutorial_id,
                overall_score=avg_score,
                avg_depth=avg_score,  # ç®€åŒ–å¤„ç†
                avg_quality=avg_score,
                avg_readability=avg_score,
                total_chapters=len(md_files),
                total_issues=total_issues,
                high_issues=high_issues,
                medium_issues=medium_issues,
                low_issues=low_issues,
            )
            
            TutorialModel.update_status(tutorial_id, EvaluationStatus.COMPLETED.value)
            
            emit("log", level="success", message=f"ğŸ‰ è¯„ä¼°å®Œæˆ!")
            emit("log", level="info", message=f"   ğŸ“ˆ ç»¼åˆè¯„åˆ†: {avg_score:.1f}")
            emit("log", level="info", message=f"   ğŸ“š è¯„ä¼°ç« èŠ‚: {len(chapters_to_evaluate)}/{len(md_files)}")
            emit("log", level="info", message=f"   ğŸ” å‘ç°é—®é¢˜: {total_issues} (ğŸ”´{high_issues} ğŸŸ¡{medium_issues} ğŸŸ¢{low_issues})")
            emit("log", level="info", message=f"   â±ï¸ è€—æ—¶: {duration} ç§’")
            
            emit("evaluation_complete",
                 tutorial_id=tutorial_id,
                 overall_score=avg_score,
                 total_chapters=len(md_files),
                 evaluated_chapters=len(chapters_to_evaluate),
                 total_issues=total_issues,
                 duration_seconds=duration)
            
            logger.info(f"è¯„ä¼°å®Œæˆ: tutorial_id={tutorial_id}, score={avg_score:.1f}, issues={total_issues}, duration={duration}s")
            
            return {
                "success": True,
                "tutorial_id": tutorial_id,
                "overall_score": avg_score,
                "total_chapters": len(md_files),
                "evaluated_chapters": len(chapters_to_evaluate),
                "total_issues": total_issues,
                "high_issues": high_issues,
                "medium_issues": medium_issues,
                "low_issues": low_issues,
                "duration_seconds": duration,
            }
            
        except Exception as e:
            logger.error(f"è¯„ä¼°å¤±è´¥: {e}", exc_info=True)
            TutorialModel.update_status(tutorial_id, EvaluationStatus.FAILED.value, str(e))
            emit("error", message=str(e))
            raise
    
    async def evaluate_tutorial(
        self, 
        tutorial_id: int,
        on_progress: Callable[[Dict], None] = None
    ) -> Dict:
        """
        è¯„ä¼°æ•™ç¨‹ (å¼‚æ­¥åŒ…è£…)
        
        Args:
            tutorial_id: æ•™ç¨‹ ID
            on_progress: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        # è°ƒç”¨åŒæ­¥ç‰ˆæœ¬
        return self.evaluate_tutorial_sync(tutorial_id, on_progress)


def init_reviewer_service(llm_service=None, search_service=None, repos_dir: str = None):
    """
    åˆå§‹åŒ– ReviewerService
    
    Args:
        llm_service: LLM æœåŠ¡å®ä¾‹
        search_service: æœç´¢æœåŠ¡å®ä¾‹
        repos_dir: Git ä»“åº“å­˜å‚¨ç›®å½•
    """
    global _reviewer_service
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_reviewer_tables()
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    _reviewer_service = ReviewerService(
        llm_service=llm_service,
        search_service=search_service,
        repos_dir=repos_dir,
    )
    
    return _reviewer_service


def get_reviewer_service() -> Optional[ReviewerService]:
    """è·å– ReviewerService å®ä¾‹"""
    return _reviewer_service
